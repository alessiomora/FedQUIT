dataset: "cifar100"
model: "ResNet18"  #or MitB0
alpha: 0.1  # alpha = 0 --> 1 class per client, -1 homogeneous
local_batch_size: 32
total_clients: 10
total_rounds: 1
active_clients: 1.0
local_epochs: 1
lr_decay: 0.998  # exponential decay per round
learning_rate: 0.1  #mnist 0.01, cifar100 0.1  # 3e-4
#learning_rate: 3e-4
retraining: False
restart_training: True  # restart training from checkpoint
resume_training: False
sample_unlearning: False
seed: 2
unlearned_cid: [0]

resuming_after_unlearning:
  algorithm: "projected_ga"
  unlearning_epochs: 5
  unlearning_lr: 0.01
  frozen_layers: 0
  early_stopping_threshold: 6.0

mode:
  max_rounds: 60
  deg_rounds: 56
  learning_rate_guidance: 0.0005

fedau:
  coefficient: 0.04
  learning_rate: 1e-1
  epochs: 10

fedosd:
  lr_unlearning: 4e-4  # in the original paper, 4e-4 (regular lr 5e-2)
  lr_recovery: 1e-6  # 1e-6
  ur: 1
  r: 10